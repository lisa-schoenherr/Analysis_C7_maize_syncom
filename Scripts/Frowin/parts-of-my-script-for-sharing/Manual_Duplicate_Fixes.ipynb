{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Manual Duplicate Fixing",
   "id": "5cf15b8a138e2685"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "55679812c0a60a3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "import ast\n",
    "import os\n",
    "from cobra.io import read_sbml_model, write_sbml_model\n",
    "import pandas as pd"
   ],
   "id": "dbe7b17a9cb28b0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "2f79881d3192749"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_gpr(gpr_str):\n",
    "    # Split on ' or ' but keep \"A and B\" as one element\n",
    "    parts = re.split(r'\\s+or\\s+', gpr_str)\n",
    "    # Strip and unify whitespace\n",
    "    parts = [' '.join(p.strip().split()) for p in parts if p.strip()]\n",
    "    return set(parts)\n",
    "\n",
    "\n",
    "def merge_gpr(del_rxn_gpr, keep_rxn_gpr):\n",
    "\n",
    "    if del_rxn_gpr == \"\" and keep_rxn_gpr == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    elif del_rxn_gpr == \"\":\n",
    "        return keep_rxn_gpr\n",
    "    elif keep_rxn_gpr == \"\":\n",
    "        return del_rxn_gpr\n",
    "\n",
    "    else:\n",
    "        del_rxn_gpr = parse_gpr(del_rxn_gpr)\n",
    "        keep_rxn_gpr = parse_gpr(keep_rxn_gpr)\n",
    "\n",
    "        merged_gpr = sorted(del_rxn_gpr.union(keep_rxn_gpr))  # Sort for consistency\n",
    "\n",
    "        return ' or '.join(merged_gpr)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fix_metabolite_duplicates(model, met_delete, met_keep, rxn_dup_pairs,):\n",
    "\n",
    "    # (0) check if met_delete is in current model and rxn_dup_pairs has right format\n",
    "    if rxn_dup_pairs != [] and not all(isinstance(pair, tuple) and len(pair) == 2 for pair in rxn_dup_pairs):\n",
    "        print(f\"check rxn_dup_pairs for correctness for {rxn_dup_pairs}\")\n",
    "\n",
    "    elif met_delete in model.metabolites:\n",
    "        # (1) delete all rxns from met_delete that are in rxn_dup_pairs if met_delete in model\n",
    "        rxns_met_delete = [rxn[0] for rxn in rxn_dup_pairs if rxn[0] in model.reactions] # all reactions that we need to delete (if they are in the current model)\n",
    "        rxns_met_keep = [rxn[1] for rxn in rxn_dup_pairs if rxn[1] in model.reactions]\n",
    "\n",
    "        for dup_pair in rxn_dup_pairs:\n",
    "            del_rxn, keep_rxn = dup_pair\n",
    "\n",
    "            # (1.1) if both rxns of one rxn_dup_pairs in model\n",
    "            if del_rxn in rxns_met_delete and keep_rxn in rxns_met_keep:\n",
    "                # (1.1.1) merge gpr onto rxn_keep\n",
    "                del_rxn_gpr = model.reactions.get_by_id(del_rxn).gene_reaction_rule\n",
    "                keep_rxn_gpr = model.reactions.get_by_id(keep_rxn).gene_reaction_rule\n",
    "                model.reactions.get_by_id(keep_rxn).gene_reaction_rule = merge_gpr(del_rxn_gpr, keep_rxn_gpr)\n",
    "\n",
    "                # (1.1.2) delete del_rxn from model\n",
    "                model.remove_reactions([model.reactions.get_by_id(del_rxn)])\n",
    "\n",
    "            # (1.2) if only keep_rxn in model, continue with next rxn\n",
    "            elif keep_rxn in rxns_met_keep:\n",
    "                continue\n",
    "\n",
    "            # (1.3) if only del_rxn in model\n",
    "            elif del_rxn in rxns_met_delete:\n",
    "                del_rxn_model = model.reactions.get_by_id(del_rxn)\n",
    "                met_delete_model = model.metabolites.get_by_id(met_delete)\n",
    "                if met_delete_model in del_rxn_model.metabolites: # should always be the case\n",
    "                    # (1.3.1) replace met_delete with met_keep in del_rxn\n",
    "                    coeff = del_rxn_model.get_coefficient(met_delete) # save stoichiometry/coefficient of met_delete\n",
    "\n",
    "                    # if met_keep doesnt exist in the model, make copy of met_delete but give it ID of met_keep\n",
    "                    # i cannot just change the id of met_delete because then (3) doesnt work so universally anymore\n",
    "                    if met_keep not in model.metabolites:\n",
    "                        original_met = model.metabolites.get_by_id(met_delete)\n",
    "                        met_keep_model = original_met.copy()\n",
    "                        met_keep_model.id = met_keep\n",
    "                        model.add_metabolites([met_keep_model])\n",
    "\n",
    "                    del_rxn_model.add_metabolites({met_keep: coeff}) # use that coefficient to add met_keep\n",
    "                    del_rxn_model.add_metabolites({met_delete: -coeff}) # delete met_delete from reaction\n",
    "\n",
    "                    # (1.3.2) replace id del_rxn with id keep_rxn\n",
    "                    del_rxn_model.id = keep_rxn\n",
    "\n",
    "            else:\n",
    "                #print(f\"Problems regarding the duplicate pair: {dup_pair} in model {model.id}. Check manually.\")\n",
    "                # both reactions are not in model, so we can continue to next pair\n",
    "                continue\n",
    "\n",
    "        # (2) check if met_delete has rxns left (these are the ones without duplicates that we want to keep)\n",
    "        left_rxns = [rxn.id for rxn in model.metabolites.get_by_id(met_delete).reactions if rxn.id not in rxns_met_delete]\n",
    "\n",
    "        # (2.1) change met_delete to met_keep in left_rxns\n",
    "        for rxn in left_rxns:\n",
    "            rxn_model = model.reactions.get_by_id(rxn)\n",
    "            coeff = rxn_model.get_coefficient(met_delete)\n",
    "\n",
    "            # if met_keep doesnt exist in the model, make copy of met_delete but give it ID of met_keep\n",
    "            # i cannot just change the id of met_delete because then (3) doesnt work so universally anymore\n",
    "            if met_keep not in model.metabolites:\n",
    "                original_met = model.metabolites.get_by_id(met_delete)\n",
    "                met_keep_model = original_met.copy()\n",
    "                met_keep_model.id = met_keep\n",
    "                model.add_metabolites([met_keep_model])\n",
    "\n",
    "            rxn_model.add_metabolites({met_keep: coeff})\n",
    "            rxn_model.add_metabolites({met_delete: -coeff})\n",
    "\n",
    "        # (3) delete met_delete\n",
    "        if len(model.metabolites.get_by_id(met_delete).reactions) == 0:\n",
    "            met = model.metabolites.get_by_id(met_delete)\n",
    "            model.metabolites.remove(met)\n",
    "        else:\n",
    "            print(f'metabolite {met_delete} cannot be deleted from {model.id} because of reaction(s): {model.metabolites.get_by_id(met_delete).reactions}')\n"
   ],
   "id": "d7ca4eb6a2298d33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fix and evaluate string from the CSV file below\n",
    "# convert strings that i get from csv file to lists and add \" \" around actual strings\n",
    "def fix_and_parse(s):\n",
    "    if not isinstance(s, str) or s.strip() == \"[]\":\n",
    "        return []\n",
    "\n",
    "    # Add quotes around unquoted reaction names like BTS, ALCD4, 34DHPACDO\n",
    "    s_fixed = re.sub(r'(?<![\\'\"])\\b([\\w\\d]+)\\b(?![\\'\"])', r\"'\\1'\", s)\n",
    "\n",
    "    try:\n",
    "        return ast.literal_eval(s_fixed)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing: {s}\\nFixed to: {s_fixed}\\nError: {e}\")\n",
    "        return []"
   ],
   "id": "4f095793e7f056e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load CSV with Duplicate Metabolites",
   "id": "1a41fb2e99275dbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load CSV with duplicate info\n",
    "# this file was created outside of these notebooks, we manually checked metabolites and their reactions to decide if we want to merge metabolites\n",
    "# the csv consists of 3 columns: (1) metabolite that is obsolete (will be removed), (2) the \"right\" metaboolite that we're gonna keep and (3) a list of tuples where each tuples contains two reactions. the first reaction is the duplicated reaction that comes from the obsolete metabolite and the second reaction is the one we're gonna keep\n",
    "metabolite_dups = pd.read_csv(\"../Datasets/Metabolite_Duplicates.csv\", sep=\";\")\n",
    "\n",
    "# Change strings from last col to list\n",
    "col = \"rxn_dup_pairs[del_rxn, keep_rxn]\"\n",
    "metabolite_dups[col] = metabolite_dups[col].apply(fix_and_parse)"
   ],
   "id": "7d21da36fedc931f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MAIN\n",
    "paths m端ssen angepasst werden, wo die Modelle sind und auch wo sie hingespeichert werden m端ssen; ebenso wie der Name der xml Datei; meine Modelle werden nach dem Einlesen alle in ein models_curation dict gespeichert, 端ber welches ich iteriere, dass m端sste bei dir wahrscheinlich auch angepasst werden"
   ],
   "id": "8dfec3b142af139b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load SBML Models\n",
    "models_path = \"/home/lisa/Dokumente/Programmierung/Models/09_macaw_fixes/\"\n",
    "models_curation = {}\n",
    "for model_name in (f for f in os.listdir(models_path) if f.endswith(\".xml\")):\n",
    "    model = read_sbml_model(f\"{models_path}/{model_name}\")\n",
    "    model.solver = \"cplex\"\n",
    "    name = str(model_name[:3]+\"_curate\")\n",
    "    models_curation[name] = model\n",
    "\n",
    "models_curation = {key: models_curation[key] for key in sorted(models_curation.keys())}  # sorts the dictionary alphabetically\n",
    "AA1_curate, AA2_curate, AA3_curate, AA4_curate, AA5_curate, AA6_curate, AA7_curate = [models_curation[f\"AA{i}_curate\"] for i in range(1, 8)]"
   ],
   "id": "aadaadb3b08a5326"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# MAIN\n",
    "for model in models_curation.values(): # go over every model\n",
    "    for index, row in metabolite_dups.iterrows(): # go over every duplicate metabolite\n",
    "        met_delete = row[\"met_delete\"]\n",
    "        met_keep = row[\"met_keep\"]\n",
    "        rxn_pairs = row[\"rxn_dup_pairs[del_rxn, keep_rxn]\"]\n",
    "\n",
    "        # Fix the current metabolite\n",
    "        fix_metabolite_duplicates(model, met_delete, met_keep, rxn_pairs)"
   ],
   "id": "2d43b2fc132c5161"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save all curated model as file\n",
    "for model_name, model in models_curation.items():\n",
    "    path = f\"../Models/10_duplicate_removal/{model_name[:3]}_deleted_duplicates.xml\"\n",
    "    write_sbml_model(model, path)"
   ],
   "id": "20d3f2f8223d8b14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
